Python
一、str 字符串 不可变对象
	1.替换 replace('','')	因为str是不可变的 所以替换虽然会替换但是并未改变内存中的值
	只是在内存中新创建了一个为替换后值的字符串，若要改变则需将改变的值赋给原有对象
二、list 
	1.在末尾增加方法 .append()
	2.删除指定下标值方法 .pop()	返回被删除的值

总结：
对于不变对象来说，调用自身的任何方法，都不会改变自身的内容，这些方法只会创建新的对象并返回。

函数
一、内置常用基本函数
	1.取绝对值abs()
	2.取对个参数中最大的数max()
	3.取最小值min()
	4.将其他数据类型转换为int int()
	5.********************float float()
	6.函数名其实就是指向一个函数对象的引用，可以将函数名赋值给一个变量
		a = abs	#将变量A指向函数abs()
		a(-1)	#所以可以通过a调用函数abs()
		1		#结果
	7.将一个证书转换成十六进制的字符串 hex()
	8.数据类型检查函数isinstance(参数,数据类型) 
二、函数的参数
	1.跟java不一样 函数名是唯一的 就算参数不同也会覆盖相同函数名的函数
	2.默认参数 
	注：默认参数必须放在后 如果放在前调用的时候会把前面默认参数覆盖掉 
		def zbf(x,y=0)
	  除非调用的时候指定
	    zbf(y=1)
	3.设置默认函数的最大好处就是降低调用函数的难度
	4.定义默认参数时 必须让默认参数指向不变对象
	5.可变参数  	*
	就是像函数中传参可以使非固定的 也就是在参数前面加一个 * 
		def sum(*number)
		sum(1,2,3...)
	6.用已有list或者tuple调用可变参数 
		nums = [1,2,3...]
		sum(*nums)
		这种写法表示把nums这个List中的所有元素作为可变参数传进去
	7.关键字参数	**
	关键字参数允许传入0个或者人一个含参数名的参数，这些关键字参数在函数内部自动组装成一个dict
		def person(name,age,**kw):
			print('name：',name,'age:',age,'other:',kw)\
		person('Bob', 35, city='Beijing')
		name: Bob age: 35 other: {'city': 'Beijing'}
		person('Adam', 45, gender='M', job='Engineer')
		name: Adam age: 45 other: {'gender': 'M', 'job': 'Engineer'}
		#传入dict 用**把dict作为参数传入函数
		>>> extra = {'city': 'Beijing', 'job': 'Engineer'}
		>>> person('Jack', 24, **extra)
		name: Jack age: 24 other: {'city': 'Beijing', 'job': 'Engineer'}
	8.命名关键字参数
		def person(name,age,*,city,job):
			print(name,abs,city,job)
	命名关键字参数需要特殊分隔符 * ，*后面的参数被视为命名关键字参数
		>>> person('Jack', 24, city='Beijing', job='Engineer')
		Jack 24 Beijing Engineer
	如果函数定义中已经有了一个可变参数，后面跟着的命名关键字参数就不再需要一个特殊分隔符*了：
		def person(name, age, *args, city, job):
		print(name, age, args, city, job)
	命名关键字参数必须传入参数名，与未知参数不同；如果没有传入参数名则在调用时酱报错
	9.参数组合 可以混合组合以上描述的所有参数 但是参数定义的顺序必须是：
	必选参数，默认参数，可变参数。命名关键字参数和关键字参数。
函数总结：
	1.对于任意函数都可以通过类似 func(-args,**kw)的形式调用它，无论他的参数时如何定义的~
	2.可变参数既可以直接传入：func(1, 2, 3)，又可以先组装list或tuple，再通过*args传入：func(*(1, 2, 3))；
	3.关键字参数既可以直接传入：func(a=1, b=2)，又可以先组装dict，再通过**kw传入：func(**{'a': 1, 'b': 2})。
	4.使用*args和**kw是Python的习惯写法，当然也可以用其他参数名，但最好使用习惯用法。
	5.命名的关键字参数是为了限制调用者可以传入的参数名，同时可以提供默认值。
	6.定义命名的关键字参数在没有可变参数的情况下不要忘了写分隔符*，否则定义的将是位置参数。
三、递归函数
	1.递归函数的有点 定义简单，逻辑清晰
	2.在计算机中，函数调用是通过栈（stack）这种数据结构实现的，每当进入一个函数调用，栈就会加一层栈帧，每当函数返回，栈就会减一层栈帧。
	由于栈的大小不是无限的，所以，递归调用的次数过多，会导致栈溢出
	3.解决递归调用栈溢出的方法是通过尾递归优化。
	4.尾递归：在函数返回的时候，调用自身并且return语句不包含表达式。这样，编译器或者计时器就可以吧尾递归做优化，
	使递归本身无论调用多少次都只占用一个栈帧，不会溢出
四、高级特性
	1.切片
		①.比如L[0:3]表示,从索引0开始取值，知道索引3为止，单不包括索引3，即所以0,1,2正好是3个元素
			如果第一个索引为0还可以省略为 L[:3]
		②.倒数的第一个索引为[-1] 
		③.取前十个数 L[:10] 取后十 L[-10:]
		取前11-20 L[11:20]	取前十每两个去一个L[:10:2]
		所有数每五个取一个 L[::5]
		④.字符串也可看做list因此也适用于切片
	总结：切片操作免去了很多地方的循环操作。
	2.迭代
		如果给定一个list或tuple，我们可以通过for循环来遍历这个list或tuple，
		这种遍历我们称为迭代（Iteration）。
		①.在python中通过 for..in来完成
		在python中for循环不仅可以用在list和tuple中也可用在其他可迭代对象上
		②.如果要对list实现类似java的下标循环时python 内置的 enumerate函数可以吧list变成索引-元素对,
		这样就可以在for循环中同事迭代索引和元素本身。
			for i,value in enumerate(['A','B','C']):
				print(i,value)
			0 A
			1 B
			2 C
	总结：任何迭代对象都可以作用于for循环，包括我们自定义的数据类型。只要符合迭代条件，就可以用for循环。
	3.列表生成式
		即List Comprehensions，是Python内置的非常简单却强大的可以用来创建list的生成式
		①.举个例子，要生成list [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]可以用list(range(1, 11))
		②.再举个例子，如果要生成[1x1, 2x2, 3x3, ..., 10x10]怎么做
			>>> L = []
			>>> for x in range(1, 11):
			...    L.append(x * x)
		在python中可以不用这么繁琐比如
		L = [x * x for x in range(1, 11)]
		还可以用两层循环，生成全排列
		[m + n for m in 'ABC' for n in 'XYZ']
		③.for循环其实可以同时使用两个甚至多个变量，比如dict的items()可以同时迭代key和value
			>>> d = {'x': 'A', 'y': 'B', 'z': 'C' }
			>>> for k, v in d.items():
			...     print(k, '=', v)
		因此，列表生成式也可以使用两个变量来生成list：
		>>> d = {'x': 'A', 'y': 'B', 'z': 'C' }
		>>> [k + '=' + v for k, v in d.items()]
		['y=B', 'x=A', 'z=C']
	4.生成器
		在Python中，这种一边循环一边计算的机制，称为生成器：generator
		①.要创建一个generator，有很多种方法。第一种方法很简单，
		只要把一个列表生成式的[]改成()，就创建了一个generator：
		>>> L = [x * x for x in range(10)]
		>>> L
		[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]
		>>> g = (x * x for x in range(10))
		>>> g
		<generator object <genexpr> at 0x1022ef630>
		②.如果一个函数定义中包含yield关键字，那么这个函数就不再是一个普通函数，而是一个generator
		③.变成generator的函数，在每次调用next()的时候执行，遇到yield语句返回，
		再次执行时从上次返回的yield语句处继续执行。
		④.在使用for循环调用generator时，发现会拿不到generatod的return语句的返回值，所以必须要捕获
		异常
	总结:generator的工作原理，它是在for循环的过程中不断计算出下一个元素，并在适当的条件结束for循环。
		对于函数改成的generator来说，遇到return语句或者执行到函数体最后一行语句，就是结束generator的指令，
		for循环随之结束。
	5.迭代器
		定义:可以被next()函数调用并不断返回下一个值的对象成为迭代器:Iterator
		①可以使用isinstance()判断一个对象是否是Iterator对象
		②.生成器都是Iterator对象，单list,dict,str虽然是Iterable(可迭代的)，却不是Iterator
		③.如果想酱list,dict,str等Iterable变成Iterator可以使用iter()函数
		④.为什么list,dict,str等数据类型不是ITerator
			因为Python的Iterator对象表示的是一个数据流,Iterator对象可以被next()函数调用并不断返回下一个
			数据，知道没有数据时抛出Stopiteration错误；可以吧这个数据流看做是一个有序序列，单我们却不能
			提前知道序列的长度，只能不断的通过next()函数实现按需计算下一个数据，所以Iterator的计算是惰性的
			只有在需要返回下一个值的时候才会计算。
			Iterator甚至可以表示一个无限大的数据流，例如全体自然数.然而用List是永远不可能存储全体自然数的
	总结：①凡是可以作用于for循环的对象都是Iterable类型
		  ②凡是可以作用于next()函数的对象都是Iterator类型，他们表示一个惰性计算的序列
		  ③集合数据类型如list,dict,str 等都是Iterable 单不是Iterator,不过可以通过iter()函数获得一个Iterator对象
		  ④python的for循环本质上就是通过不断调用next()函数实现的例如
		  for x in [1,2,3,4]:
			  pass
		  等价于
		  it = iter([1,2,3,4])
		  while True:
				try:
					#获取下一个值
					x = next(it)
				except StopIteration:
					#没有下一个值了 退出循环
					break
五、函数式编程
	函数是Python内建支持的一种封装，我们通过把大段代码拆成函数，通过一层一层的函数调用，就可以把复杂任务分解成简单的任务，
	这种分解可以称之为面向过程的程序设计。函数就是面向过程的程序设计的基本单元。
	1.高阶函数
		①变量可以指向函数
		②函数名也是变量
		③传入参数 既然变量可以只想函数，函数的参数也能接受变量，那么一个函数就可以接受另一个函数作为参数，
		这种函数就称之为高阶函数。举一个最简单的高阶函数
		def add(x,y,add):
			return f(x) + f(y)
		当调用add(-5,6,abs)的时候，推导过程为
		x = -5,y = 6,f = abs
		f(x) + f(y) ==>abs(-5) + abs(+) ==> 11
	总结:把函数作为参数传入，这样的函数被称为高阶函数，函数式编程就是这样高度抽象的变成范式
	2.map/reduce
		①.map()函数接受两个函数,一个是函数，一个是Iterable,map将传入的函数一次作用于序列的每个元素，
		并把返回结果作为新的Iteratro返回。
		②.reduce()把一个函数作用在一个序列[x1,x2,...xn],这个函数必须接收两个参数,reduce把结果和序列的
		下一个元素做累计计算，其效果就是:reduce(f, [x1, x2, x3, x4]) = f(f(f(x1, x2), x3), x4)
	3.filter
		①.Pyhton内建的filter()函数用于过滤序列和map()类似，filter()也接收一个函数和一个序列。和map()不同的是，
		filter()把传入的函数依次作用于每个元素，然后根据返回值是True还是False决定保留还是丢弃该元素。
		例：
			def is_odd(n):
			return n % 2 == 1
			list(filter(is_odd, [1, 2, 4, 5, 6, 9, 10, 15]))
			# 结果: [1, 5, 9, 15]
		②.filter()函数返回的是一个Iterator，也就是一个惰性序列，所以要强迫filter()完成计算结果，
		需要用list()函数获得所有结果并返回list。
	总结:filter()的作用是从一个序列中筛出符合条件的元素。由于filter()使用了惰性计算，所以只有在取filter()结果的时候，
	才会真正筛选并每次返回下一个筛出的元素。
	4.sorted	排序算法
		①.sorted()可以对list进行排序
		②.还可以接收一个key函数来实现自定义的排序，例如按绝对值大小排序
		>>> sorted([36, 5, -12, 9, -21], key=abs)
		[5, 9, -12, -21, 36]
		③.要进行反向排序，不必改动key函数，可以传入第三个参数reverse=True
	总结：sorted()也是一个高阶函数。用sorted()排序的关键在于实现一个映射函数。
	5.返回函数
		①.高阶函数除了可以接受函数作为参数外，还可以把函数作为结果值返回。
		②.闭包。注意到返回的函数在其定义内部引用了局部变量args，所以，当一个函数返回了一个函数后，
		其内部的局部变量还被新函数引用，所以，闭包用起来简单，实现起来可不容易。
		③.返回闭包时牢记的一点就是：返回函数不要引用任何循环变量，或者后续会发生变化的变量。	
	总结:一个函数可以返回一个计算结果，也可以返回一个函数。返回一个函数时，牢记该函数并未执行，
		返回函数中不要引用任何可能会变化的变量。
	6.匿名函数
		①.关键字lambda表示匿名函数，冒号前面的x表示函数参数。
		②.匿名函数有个限制，就是只能有一个表达式，不用写return，返回值就是该表达式的结果。
		③.用匿名函数有个好处，因为函数没有名字，不必担心函数名冲突。此外，匿名函数也是一个函数对象，
		也可以把匿名函数赋值给一个变量，再利用变量来调用该函数:
		>>> f = lambda x: x * x
		>>> f
		<function <lambda> at 0x101c6ef28>
		>>> f(5)
		25
	总结:Python对匿名函数的支持有限，只有一些简单的情况下可以使用匿名函数。
	7.装饰器
		①.由于函数也是一个对象，而且函数对象可以被赋值给变量，所以，通过变量也能调用该函数。
		>>> def now():
		...     print('2015-3-25')
		...
		>>> f = now
		>>> f()
		2015-3-25
		②.函数对象有一个__name__属性，可以拿到函数的名字 （注意前后都有两个下划线）
		③.假设我们要增强now()函数的功能，比如，在函数调用前后自动打印日志，但又不希望修改now()函数的定义，
			这种在代码运行期间动态增加功能的方式，称之为“装饰器”（Decorator）
			调用now()函数，不仅会运行now()函数本身，还会在运行now()函数前打印一行日志
			把@log放到now()函数的定义处，相当于执行了语句：now = log(now)
		④.>>> now = log('execute')(now)
			首先执行log('execute')，返回的是decorator函数，再调用返回的函数，参数是now函数，返回值最终是wrapper函数。
		⑤.不需要编写wrapper.__name__ = func.__name__这样的代码,Python内置的functools.wraps就是干这个事的:
			import functools
			def log(func):
				@functools.wraps(func)
				def wrapper(*args, **kw):
					print('call %s():' % func.__name__)
					return func(*args, **kw)
				return wrapper
	总结:在面向对象（OOP）的设计模式中，decorator被称为装饰模式。OOP的装饰模式需要通过继承和组合来实现，而Python除了能支持OOP的decorator外，
	直接从语法层次支持decorator。Python的decorator可以用函数实现，也可以用类实现。
	decorator可以增强函数的功能，定义起来虽然有点复杂，但使用起来非常灵活和方便。
	8.偏函数
		简单总结functools.partial的作用就是，把一个函数的某些参数给固定住（也就是设置默认值），返回一个新的函数，调用这个新函数会更简单。
		int2 = functools.partial(int, base=2)
		实际上固定了int()函数的关键字参数base，也就是：
		int2('10010')
		相当于：
		kw = { 'base': 2 }
		int('10010', **kw)
		当传入:
		max2 = functools.partial(max, 10)
		实际上会把10作为*args的一部分自动加到左边，也就是：
		max2(5, 6, 7)
		相当于：
		args = (10, 5, 6, 7)
		max(*args)
	总结:当函数的参数个数太多，需要简化时，使用functools.partial可以创建一个新的函数，这个新函数可以固定住原函数的部分参数，从而在调用时更简单。
六、模块
	在Python中，一个.py文件就称之为一个模块（Module）。
	为了避免模块名冲突，Python又引入了按目录来组织模块的方法，称为包（Package）。
	每一个包目录下面都会有一个__init__.py的文件，这个文件是必须存在的，否则，Python就把这个目录当成普通目录，而不是一个包。__init__.py可以是空文件，
	也可以有Python代码，因为__init__.py本身就是一个模块，
	1.使用模块
	2.作用域
		①.在一个模块中，我们可能会定义很多函数和变量，但有的函数和变量我们希望给别人使用，有的函数和变量我们希望仅仅在模块内部使用。在Python中，是通过_前缀来实现的。
		②.类似__xxx__这样的变量是特殊变量，可以被直接引用，但是有特殊用途，比如上面的__author__，__name__就是特殊变量，hello模块定义的文档注释也可以用特殊变量__doc__访问，
		我们自己的变量一般不要用这种变量名；
		③.类似_xxx和__xxx这样的函数或变量就是非公开的（private），不应该被直接引用，比如_abc，__abc等；
	总结:外部不需要引用的函数全部定义成private，只有外部需要引用的函数才定义为public。
	3.安装三方模块
		使用pip工具进行下载对应三方模块
	4.模块搜索路径
		①.当我们试图加载一个模块时，Python会在指定的路径下搜索对应的.py文件，如果找不到，就会报错
		②.默认情况下，Python解释器会搜索当前目录、所有已安装的内置模块和第三方模块，搜索路径存放在sys模块的path变量中
		③.如果我们要添加自己的搜索目录，有两种方法
			①.直接修改sys.path，添加要搜索的目录：
				 import sys
				 sys.path.append('/Users/michael/my_py_scripts')
			②.设置环境变量PYTHONPATH，该环境变量的内容会被自动添加到模块搜索路径中。设置方式与设置Path环境变量类似。注意只需要添加你自己的搜索路径，
			Python自己本身的搜索路径不受影响。
七、面向对象编程
	1.类和实例
		①.面向对象最重要的概念就是类（Class）和实例（Instance），必须牢记类是抽象的模板，比如Student类，而实例是根据类创建出来的一个个具体的“对象”，
		每个对象都拥有相同的方法，但各自的数据可能不同。
		②.class后面紧接着是类名，类名通常是大写开头的单词，紧接着是(object)表示该类是从哪个类继承下来的，
		通常，如果没有合适的继承类，就使用object类，这是所有类最终都会继承的类。
		③.定义好了类，就可以根据类创建出实例，创建实例是通过类名+()实现的
		④.可以自由地给一个实例变量绑定属性
		⑤.由于类可以起到模板的作用，因此，可以在创建实例的时候，把一些我们认为必须绑定的属性强制填写进去。通过定义一个特殊的__init__方法，在创建实例的时候，
		就把name，score等属性绑上去
		⑥.注意到__init__方法的第一个参数永远是self，表示创建的实例本身，因此，在__init__方法内部，就可以把各种属性绑定到self，因为self就指向创建的实例本身。
		⑦.和普通的函数相比，在类中定义的函数只有一点不同，就是第一个参数永远是实例变量self，并且，调用时，不用传递该参数。除此之外，类的方法和普通函数没有什么区别，
		所以，你仍然可以用默认参数、可变参数、关键字参数和命名关键字参数。
	2.数据封装
		①.面向对象编程的一个重要特点就是数据封装。在类中，每个实例就拥有各自的数据。我们可以通过函数来访问这些数据
		②.既然实例本身就拥有这些数据，要访问这些数据，就没有必要从外面的函数去访问，可以直接在类的内部定义访问数据的函数，这样，就把“数据”给封装起来了。
		这些封装数据的函数是和类本身是关联起来的，我们称之为类的方法
		③.要定义一个方法，除了第一个参数是self外，其他和普通函数一样。要调用一个方法，只需要在实例变量上直接调用，除了self不用传递，其他参数正常传入
		④.这样一来，我们从外部看类，就只需要知道，创建实例需要给出的参数，而如何打印，都是在类的内部定义的，这些数据和逻辑被“封装”起来了，
		调用很容易，但却不用知道内部实现的细节。
		⑤.封装的另一个好处是可以给类增加新的方法，同样的，新增方法可以直接在实例变量上调用，不需要知道内部实现细节
	总结:
	类是创建实例的模板，而实例则是一个一个具体的对象，各个实例拥有的数据都互相独立，互不影响；
	方法就是与实例绑定的函数，和普通函数不同，方法可以直接访问实例的数据；
	通过在实例上调用方法，我们就直接操作了对象内部的数据，但无需知道方法内部的实现细节。
	和静态语言不同，Python允许对实例变量绑定任何数据，也就是说，对于两个实例变量，虽然它们都是同一个类的不同实例，但拥有的变量名称都可能不同：
	3.访问限制
		①.如果要让内部属性不被外部访问，可以把属性的名称前加上两个下划线__，在Python中，实例的变量名如果以__开头，就变成了一个私有变量（private），
		只有内部可以访问，外部不能访问，这样就确保了外部代码不能随意修改对象内部的状态，这样通过访问限制的保护，代码更加健壮。
		②.如果外部代码要获取实例中属性的值，可以在类中添加get方法，要更改实例中的属性值，也就是在类中添加set方法，跟java的get,set方法一致
		③.为什么要定义一个方法大费周折？因为在方法中，可以对参数做检查，避免传入无效的参数：
			  def set_score(self, score):
					if 0 <= score <= 100:
						self.__score = score
					else:
						raise ValueError('bad score')
		④.在Python中，变量名类似__xxx__的，也就是以双下划线开头，并且以双下划线结尾的，是特殊变量，特殊变量是可以直接访问的，不是private变量，
		所以，不能用__name__、__score__这样的变量名。
	4.继承和多态
		①.在OOP程序设计中，当我们定义一个class的时候，可以从某个现有的class继承，新的class称为子类（Subclass），
		而被继承的class称为基类、父类或超类（Base class、Super class）。
		②.当子类和父类都存在相同的方法时，我们说，子类的方法覆盖了父类的方法，在代码运行的时候，总是会调用子类的。
		这样，我们就获得了继承的另一个好处：多态。
		③.判断一个变量是否是某个类型可以用isinstance()判断
		③.静态语言vs动态语言：
			对于静态语言（例如Java）来说，如果需要传入Animal类型，则传入的对象必须是Animal类型或者它的子类，否则，将无法调用run()方法。
			对于Python这样的动态语言来说，则不一定需要传入父类型。我们只需要保证传入的对象有函数调用的方法就可以了
	总结:
		①.继承可以把父类的所有功能都直接拿过来，这样就不必重零做起，子类只需要新增自己特有的方法，也可以把父类不适合的方法覆盖重写。
		②.动态语言的鸭子类型特点决定了继承不像静态语言那样是必须的。
	5.获取对象信息
		①.使用type(),函数返回的类型是对应的Class类型
		②.判断一个对象是否是函数的时候可以使用types模块中定义的常量
		③.使用isinstance()
		④.使用dir()，可以获取一个对象的所有属性和方法
		⑤.仅仅把属性和方法列出来是不够的，配合getattr()、setattr()以及hasattr()，我们可以直接操作一个对象的状态
		⑥.如果试图获取不存在的属性，会抛出AttributeError的错误，这个时候可以传入一个default的参数，如果不存在返回默认值
			getattr(obj, 'z', 404)
	小结:
		①.通过内置的一系列函数，我们可以对任意一个Python对象进行剖析，拿到其内部的数据。要注意的是，只有在不知道对象信息的时候，我们才会去获取对象信息。如果可以直接写：
			sum = obj.x + obj.y
		就不要写：
			sum = getattr(obj, 'x') + getattr(obj, 'y')
		②.一个正确的用法的例子如下：
			def readImage(fp):
				if hasattr(fp, 'read'):
					return readData(fp)
				return None
		假设我们希望从文件流fp中读取图像，我们首先要判断该fp对象是否存在read方法，如果存在，则该对象是一个流，如果不存在，则无法读取。hasattr()就派上了用场
		在Python这类动态语言中，根据鸭子类型，有read()方法，不代表该fp对象就是一个文件流，它也可能是网络流，也可能是内存中的一个字节流，但只要read()方法返回的是有效的图像数据，
		就不影响读取图像的功能。
	6.实例属性和类属性
		①.由于Python是动态语言，根据类创建的实例可以任意绑定属性。
		②.给实例绑定属性的方法是通过实例变量，或者通过self变量
		③.当我们定义了一个类属性后，这个属性虽然归类所有，但类的所有实例都可以访问到
		④.不要把实例属性和类属性使用相同的名字，因为相同名称的实例属性将屏蔽掉类属性，但是当你删除实例属性后，再使用相同的名称，访问到的将是类属性。
八、面向对象高级编程
		数据封装、继承和多态只是面向对象程序设计中最基础的3个概念。在Python中，面向对象还有很多高级特性，允许我们写出非常强大的功能。
	1.使用__slots__
		①.正常情况下，当我们定义了一个class，创建了一个class的实例后，我们可以给该实例绑定任何属性和方法，这就是动态语言的灵活性。
		②.给实例绑定一个属性：
			s = Student()
			s.name = 'Michael' # 动态给实例绑定一个属性
		③.给实例绑定一个方法
			>>> def set_age(self, age): # 定义一个函数作为实例方法
			...     self.age = age
			...
			>>> from types import MethodType
			>>> s.set_age = MethodType(set_age, s) # 给实例绑定一个方法
			>>> s.set_age(25) # 调用实例方法
		④.但是，给一个实例绑定的方法，对另一个实例是不起作用的，为了给所有实例都绑定方法，可以给class绑定方法：
			>>> def set_score(self, score):
			...     self.score = score
			...
			>>> Student.set_score = set_score
		⑤.通常情况下，方法可以直接定义在class中，但动态绑定允许我们在程序运行的过程中动态给class加上功能，这在静态语言中很难实现。			
		⑥.如果我们想要限制实例的属性，为了达到限制的目的，Python允许在定义class的时候，定义一个特殊的__slots__变量，来限制该class实例能添加的属性：
			class Student(object):
				__slots__ = ('name', 'age') # 用tuple定义允许绑定的属性名称
		⑦.由于'score'没有被放到__slots__中，所以不能绑定score属性，试图绑定score将得到AttributeError的错误。
		⑧.使用__slots__要注意，__slots__定义的属性仅对当前类实例起作用，对继承的子类是不起作用的
		⑨.除非在子类中也定义__slots__，这样，子类实例允许定义的属性就是自身的__slots__加上父类的__slots__
	2.使用@property
		①.Python内置的@property装饰器就是负责把一个方法变成属性调用的
		②.把一个getter方法变成属性，只需要加上@property就可以了，此时，@property本身又创建了另一个装饰器@score.setter，
		负责把一个setter方法变成属性赋值，于是，我们就拥有一个可控的属性操作
		③.使用@property让我们在对实例属性操作的时候，就知道该属性很可能不是直接暴露的，而是通过getter和setter方法来实现的
		④.还可以定义只读属性，只定义getter方法，不定义setter方法就是一个只读属性
	小结：@property广泛应用在类的定义中，可以让调用者写出简短的代码，同时保证对参数进行必要的检查，这样，程序运行时就减少了出错的可能性。
	3.多重集成
		①.继承是面向对象编程的一个重要的方式，因为通过继承，子类就可以扩展父类的功能，python允许多继承这样一个子类就可以同时获得多个父类的所有功能：
			class name(father1,father2 ..)
		②.MixIn：在设计类的继承关系时，通常，主线都是单一继承下来的，。但是，如果需要“混入”额外的功能，通过多重继承就可以实现，这种设计通常称之为MixIn
		③.MixIn的目的就是给一个类增加多个功能，这样，在设计类的时候，我们优先考虑通过多重继承来组合多个MixIn的功能，而不是设计多层次的复杂的继承关系。
	小结:
		由于Python允许使用多重继承，因此，MixIn就是一种常见的设计。
		只允许单一继承的语言（如Java）不能使用MixIn的设计。
	4.定制类
		①.看到类似__slots__这种形如__xxx__的变量或者函数名就要注意，这些在Python中是有特殊用途的。
		②.__str__()：		#相当于java中的toString()
			 class Student(object):
				...     def __init__(self, name):
				...         self.name = name
				...     def __str__(self):
				...         return 'Student object (name: %s)' % self.name
				...
			 print(Student('Michael'))
			 Student object (name: Michael)
		③.如果直接敲击变量而不是用print打印实例 显示的实例依旧不好看，因为直接显示变量调用的不是__str__()而是__repr__(),
		两者的区别是__str__()返回用户看到的字符串，而__repr__()返回程序开发者看到的字符串，也就是说，__repr__()是为调试服务的。
		④.解决办法是再定义一个__repr__()。但是通常__str__()和__repr__()代码都是一样的，所以，有个偷懒的写法：
			class Student(object):
				def __init__(self, name):
					self.name = name
				def __str__(self):
					return 'Student object (name=%s)' % self.name
				__repr__ = __str__
		⑤.__iter__ :如果一个类想要被for..in循环，类似list或tuple那样，就必须实现一个__iter__()方法，该方法返回一个迭代对象，
		然后，Python的for循环就会不断调用该迭代对象的__next__()方法拿到循环的下一个值，直到遇到StopIteration错误时退出循环。
			详见test_fib.py
		⑥.__getiterm__:Fib实例虽然能作用于for循环并且看起来和list相似，但是并不能当成List来使用，如果想表现的像List一样就需要__getitem__()函数
		⑦.list中有切片方法，但是我们的Fib实例缺报错，因为__getitem__()传入的参数可能是int，也可能是一个切片对象slice所以要惊醒判断
		⑧.与__getiterm__()对应的是__setitem__(),做影视把对象是做List活dict来对集合进行赋值，当然还有一个__delitem__(),用于删除集合中的特定元素
		⑨.__getattr__():当我们在调用一个类的方法活属性时，如果不存在就会报错，二因为python的机制也就是__getattr__()方法，会动态返回一个属性
		10.利用完全动态的__getattr__，我们可以写出一个链式调用：
			class Chain(object):
			def __init__(self, path=''):
				self._path = path
				
			def __getattr__(self, path):
				return Chain('%s/%s' % (self._path, path))
				
			def __str__(self):
				return self._path
			__repr__ = __str__
		11.__call__:定义之后，就可以直接对实例进行调用
			还可以定义参数。对实例进行直接调用就好比对一个函数进行调用一样，所以你完全可以把对象看成函数，
			把函数看成对象，因为这两者之间本来就没啥根本的区别。
		12.更多的时候，我们需要判断一个对象是否能被调用，能被调用的对象就是一个Callable对象，比如函数和我们上面定义的带有__call__()的类实例
			通过callable()函数，我们就可以判断一个对象是否是“可调用”对象。
	小结:Python的class允许定义许多定制方法，可以让我们非常方便地生成特定的类。
	5.使用枚举类
		①.枚举类型定义一个class类型，然后，每个常量都是class的一个唯一实例。Python提供了Enum类来实现这个功能
		②.value属性则是自动赋给成员的int常量，默认从1开始计数
		③.如果需要更精确地控制枚举类型，可以从Enum派生出自定义类，@unique装饰器可以帮助我们检查保证没有重复值
	小结：Enum可以把一组相关常量定义在一个class中，且class不可变，而且成员可以直接比较。
	6.使用元类
		①.type():
			type()函数可以查看一个类型或变量的类型，Hello是一个class，它的类型就是type，而h是一个实例，它的类型就是class Hello。
		②.我们说class的定义是运行时动态创建的，而创建class的方法就是使用type()函数
		③.type()函数既可以返回一个对象的类型，又可以创建出新的类型，比如，我们可以通过type()函数创建出Hello类，而无需通过class Hello(object)...的定义
		④.要创建一个Class对象,type()函数一次传入3个参数
			①.class的名称
			②.继承的父类集合，注意Python支持多重继承，如果只有一个父类，别忘了tuple的单元素写法	#(object,)
			③.class的方法名称与函数绑定
		⑤.通过type()函数创建的类和直接写class是完全一样的，因为Python解释器遇到class定义时，仅仅是扫描一下class定义的语法，然后调用type()函数创建出class
		⑥.metaclass：
			①.除了使用type()动态创建类以外，要控制类的创建行为，还可以使用metaclass
			②.metaclass，直译为元类，简单的解释就是：当我们定义了类以后，就可以根据这个类创建出实例，所以：先定义类，然后创建实例。
			③.metaclass允许你创建类或者修改类。换句话说，你可以把类看成是metaclass创建出来的“实例”
	小结：metaclass是Python中非常具有魔术性的对象，它可以改变类创建时的行为。这种强大的功能使用起来务必小心。
九、错误、调试和测试
	Python内置了一套异常处理机制，来帮助我们进行错误处理。
	我们也需要跟踪程序的执行，查看变量的值是否正确，这个过程称为调试。Python的pdb可以让我们以单步方式执行代码。
	1.错误处理
		①.Python内置了一套try...except...finally...的错误处理机制
		②.如果错误没有发生except语句块就不会被执行，但是如果有finally就一定会执行不论有没有错误发生
		③.Python的错误其实也是class，所有的错误类型都继承自BaseException，所以在使用except时需要注意的是，它不但捕获该类型的错误，还把其子类也“一网打尽”。
	2.调用堆栈
		①.如果错误没有被捕获，它就会一直往上抛，最后被Python解释器捕获，打印一个错误信息，然后程序退出。
		②.记录错误，Python内置的logging模块可以非常容易地记录错误信息
		④.抛出错误，因为错误是class，捕获一个错误就是捕获到该class的一个实例。因此，错误并不是凭空产生的，而是有意创建并抛出的。
	小结:
	①.Python内置的try...except...finally用来处理错误十分方便。出错时，会分析错误信息并定位错误发生的代码位置才是最关键的。
	②.程序也可以主动抛出错误，让调用者来处理相应的错误。但是，应该在文档中写清楚可能会抛出哪些错误，以及错误产生的原因。
	3.调试：
		①.简单暴力的print()但是将来还需要删除他，并且运行结果会包含很多垃圾信息
		②.断言(assert):
			def foo(s):
				n = int(s)
				assert n != 0, 'n is zero!'
				return 10 / n

			def main():
				foo('0')
			①.assert的意思是表达式n!=0应该是True,否则，根据程序运行的逻辑，后面的代码肯定会出错。
			②.如果断言失败，assert语句本身就会抛出AssertionError
		③.程序中如果到处充斥着assert，和print()相比也好不到哪去。不过，启动Python解释器时可以用-O参数来关闭assert
			关闭后，你可以把所有的assert语句当成pass来看
		④.logging:
			①.把print()替换为logging是第3种方式，和assert比，logging不会抛出错误，而且可以输出到文件
			②.它允许你指定记录信息的级别，有debug，info，warning，error等几个级别，当我们指定level=INFO时，logging.debug就不起作用了。
			③.logging的另一个好处是通过简单的配置，一条语句可以同时输出到不同的地方，比如console和文件。
		⑤.pdb:以参数-m pdb启动后，输入命令l来查看代码,输入命令n可以单步执行代码,任何时候都可以输入命令p 变量名来查看变量
		⑥.pdb.set_trace()
			这个方法也是用pdb，但是不需要单步执行，我们只需要import pdb，然后，在可能出错的地方放一个pdb.set_trace()，就可以设置一个断点
			行代码，程序会自动在pdb.set_trace()暂停并进入pdb调试环境，可以用命令p查看变量，或者用命令c继续运行
	小结：写程序最痛苦的事情莫过于调试，程序往往会以你意想不到的流程来运行，你期待执行的语句其实根本没有执行，这时候，就需要调试了。
		  虽然用IDE调试起来比较方便，但是最后你会发现，logging才是终极武器。
	4.单元测试	
		①.单元测试是用来对一个模块、一个函数或者一个类来进行正确性检验的测试工作。
		②.编写单元测试时，我们需要编写一个测试类，从unittest.TestCase继承。
		③.以test开头的方法就是测试方法，不以test开头的方法不被认为是测试方法，测试的时候不会被执行。
		④.对每一类测试都需要编写一个test_xxx()方法。由于unittest.TestCase提供了很多内置的条件判断，我们只需要调用这些方法就可以断言输出是否是我们所期望的。最常用的断言就是assertEqual()：
		⑤.另一种重要的断言就是期待抛出指定类型的Error，比如通过d['empty']访问不存在的key时，断言会抛出KeyError：
			with self.assertRaises(KeyError):
				value = d['empty']
		   通过d.empty访问不存在的key时，我们期待抛出AttributeError
			with self.assertRaises(AttributeError):
				value = d.empty
		⑥.运行单元测试，一旦编写好单元测试，我们就可以运行单元测试。最简单的运行方式是在最后加上两行代码
			if __name__ == '__main__':
				unittest.main()
		⑦.另一种方法是在命令行通过参数-m unittest xx.py 直接运行单元测试
		⑧.setUp与tearDown，这两个方法会分别在每调用一个测试方法的前后分别被执行。
	小结：①.单元测试可以有效地测试某个程序模块的行为，是未来重构代码的信心保证。
		  ②.单元测试的测试用例要覆盖常用的输入组合、边界条件和异常。
		  ③.单元测试代码要非常简单，如果测试代码太复杂，那么测试代码本身就可能有bug。
		  ④.单元测试通过了并不意味着程序就没有bug了，但是不通过程序肯定有bug。
	5.文档测试
		if __name__=='__main__':
			import doctest
			doctest.testmod()
		当模块正常导入时，doctest不会被执行。只有在命令行直接运行时，才执行doctest。所以，不必担心doctest会在非测试环境下执行。
	小结:
		doctest非常有用，不但可以用来测试，还可以直接作为示例代码。通过某些文档生成工具，就可以自动把包含doctest的注释提取出来。用户看文档的时候，同时也看到了doctest。
十、IO编程
		同步IO
		异步IO
	1.文件读写
		①.要以读文件的模式打开一个文件对象，使用Python内置的open()函数，传入文件名和标示符
		②.如果文件不存在，open()函数就会抛出一个IOError的错误，并且给出错误码和详细的信息告诉你文件不存在
		③.如果文件打开成功，接下来，调用read()方法可以一次读取文件的全部内容，Python把内容读到内存，用一个str对象表示	
		④.最后一步是调用close()方法关闭文件。文件使用完毕后必须关闭，因为文件对象会占用操作系统的资源，并且操作系统同一时间能打开的文件数量也是有限的
		⑤.由于文件读写时都有可能产生IOError，一旦出错，后面的f.close()就不会调用。所以，为了保证无论是否出错都能正确地关闭文件，我们可以使用try ... finally来实现：
			try:
				f = open('/path/to/file', 'r')
				print(f.read())
			finally:
				if f:
					f.close()
		⑥.但是每次都这么写实在太繁琐，所以，Python引入了with语句来自动帮我们调用close()方法：
			with open('/path/to/file', 'r') as f:
				print(f.read())
			这和前面的try ... finally是一样的，但是代码更佳简洁，并且不必调用f.close()方法。
		⑦.调用read()会一次性读取文件的全部内容，如果文件有10G，内存就爆了，所以，要保险起见，可以反复调用read(size)方法，每次最多读取size个字节的内容。
		⑧.另外，调用readline()可以每次读取一行内容，调用readlines()一次读取所有内容并按行返回list。因此，要根据需要决定怎么调用。
		⑨.如果文件很小，read()一次性读取最方便；如果不能确定文件大小，反复调用read(size)比较保险；如果是配置文件，调用readlines()最方便
	2.file-like Object
		①.像open()函数返回的这种有个read()方法的对象，在Python中统称为file-like Object。
		②.除了file外，还可以是内存的字节流，网络流，自定义流等等。file-like Object不要求从特定类继承，只要写个read()方法就行。
		③.StringIO就是在内存中创建的file-like Object，常用作临时缓冲。
	3.二进制文件
		要读取二进制文件，比如图片、视频等等，用'rb'模式打开文件即可
	4.字符编码
		①.要读取非UTF-8编码的文本文件，需要给open()函数传入encoding参数，例如，读取GBK编码的文件：
			>>> f = open('/Users/michael/gbk.txt', 'r', encoding='gbk')
			>>> f.read()
			'测试'
		②.遇到有些编码不规范的文件，你可能会遇到UnicodeDecodeError，因为在文本文件中可能夹杂了一些非法编码的字符。遇到这种情况，open()函数还接收一个errors参数，
			表示如果遇到编码错误后如何处理。最简单的方式是直接忽略
	5.写文件
		①.写文件和读文件是一样的，唯一区别是调用open()函数时，传入标识符'w'或者'wb'表示写文本文件或写二进制文件
		②.你可以反复调用write()来写入文件，但是务必要调用f.close()来关闭文件。当我们写文件时，操作系统往往不会立刻把数据写入磁盘，而是放到内存缓存起来，空闲的时候再慢慢写入。
		只有调用close()方法时，操作系统才保证把没有写入的数据全部写入磁盘。忘记调用close()的后果是数据可能只写了一部分到磁盘，剩下的丢失了。所以，还是用with语句来得保险：
			with open('/Users/michael/test.txt', 'w') as f:
				f.write('Hello, world!')
		③.要写入特定编码的文本文件，请给open()函数传入encoding参数，将字符串自动转换成指定编码。
	小结：在Python中，文件读写是通过open()函数打开的文件对象完成的。使用with语句操作文件IO是个好习惯。
	6.StringIO和BytesIO
		1.StringIO：
			StringIO顾名思义就是在内存中读写str
			要把str写入StringIO，我们需要先创建一个StringIO，然后，像文件一样写入即可。
			getvalue()方法用于获得写入后的str。
		要读取StringIO，可以用一个str初始化StringIO，然后，像读文件一样读取
		2.BytesIO:
			StringIO操作的只能是str，如果要操作二进制数据，就需要使用BytesIO
			BytesIO实现了在内存中读写bytes，我们创建一个BytesIO，然后写入一些bytes
			>>> from io import BytesIO
			>>> f = BytesIO()
			>>> f.write('中文'.encode('utf-8'))
			6
			>>> print(f.getvalue())
			b'\xe4\xb8\xad\xe6\x96\x87'
			写入的不是str，而是经过UTF-8编码的bytes。
			和StringIO类似，可以用一个bytes初始化BytesIO，然后，像读文件一样读取
	小结：StringIO和BytesIO是在内存中操作str和bytes的方法，使得和读写文件具有一致的接口。
	7.操作文件和目录
		1.Python内置的os模块也可以直接调用操作系统提供的接口函数，如果是posix，说明系统是Linux、Unix或Mac OS X，如果是nt，就是Windows系统。
		2.要获取详细的系统信息，可以调用uname()函数，值得注意的是uname()函数在win上不提供，也就是说os模块的某些函数是跟操作系统有关的
		3.环境变量
			在操作系统中定义的环境变量，全部保存在os.environ这个变量中，可以直接查看
			要获取某个环境变量的值可以调用os.environ.get('key')
		4.操作文件和目录
			操作文件和目录的函数一部分放在os模块中，一部分放在os.path模块中
			复制文件的函数居然在os模块中不存在，幸运的是shutil模块提供了copyfile()的函数，你还可以在shutil模块中找到很多实用函数，它们可以看做是os模块的补充。
	小结:
		Python的os模块封装了操作系统的目录和文件操作，要注意这些函数有的在os模块中，有的在os.path模块中。
	8.序列化
		1.Python提供了pickle模块来实现序列化
			1.pickle.dumps()方法把任意对象序列化成一个bytes，然后，就可以把这个bytes写入文件。或者用另一个方法pickle.dump()直接把对象序列化后写入一个file-like Object
			2.当我们要把对象从磁盘读到内存时，可以先把内容读到一个bytes，然后用pickle.loads()方法反序列化出对象，也可以直接用pickle.load()方法从一个file-like Object中直接反序列化出对象
		2.Pickle的问题和所有其他编程语言特有的序列化问题一样，就是它只能用于Python，并且可能不同版本的Python彼此都不兼容，因此，只能用Pickle保存那些不重要的数据，不能成功地反序列化也没关系
	9.JSON
		JSON类型 		Python类型
		{} 				dict
		[] 				list
		"string" 		str
		1234.56 		int或float
		true/false 		True/False
		null 			None
		1.Python内置的json模块提供了非常完善的Python对象到JSON格式的转换：
			>>> import json
			>>> d = dict(name='Bob', age=20, score=88)
			>>> json.dumps(d)
			'{"age": 20, "score": 88, "name": "Bob"}'
		2.dumps()方法返回一个str，内容就是标准的JSON。类似的，dump()方法可以直接把JSON写入一个file-like Object
		3.要把JSON反序列化为Python对象，用loads()或者对应的load()方法，前者把JSON的字符串反序列化，后者从file-like Object中读取字符串并反序列化
		4.由于JSON标准规定JSON编码是UTF-8，所以我们总是能正确地在Python的str与JSON的字符串之间转换。
	10.JSON进阶
		1.Python的dict对象可以直接序列化为JSON的{}，不过，很多时候，我们更喜欢用class表示对象
		2.默认情况下，dumps()方法不知道如何将Student实例变为一个JSON的{}对象。可选参数default就是把任意一个对象变成一个可序列为JSON的对象，
			我们只需要为'类'专门写一个转换函数，再把函数传进去即可
		3.通常class的实例都有一个__dict__属性，它就是一个dict，用来存储实例变量。也有少数例外，比如定义了__slots__的class
		4.同样的道理，如果我们要把JSON反序列化为一个Student对象实例，loads()方法首先转换出一个dict对象，然后，我们传入的object_hook函数负责把dict转换为Student实例
	小结:
		1.Python语言特定的序列化模块是pickle，但如果要把序列化搞得更通用、更符合Web标准，就可以使用json模块。
		2.json模块的dumps()和loads()函数是定义得非常好的接口的典范。当我们使用时，只需要传入一个必须的参数。
		  但是，当默认的序列化或反序列机制不满足我们的要求时，我们又可以传入更多的参数来定制序列化或反序列化的规则，既做到了接口简单易用，又做到了充分的扩展性和灵活性。
十一、进程和线程
	线程是最小的执行单元，而进程由至少一个线程组成。如何调度进程和线程，完全由操作系统决定，程序自己不能决定什么时候执行，执行多长时间。
	多进程和多线程的程序涉及到同步、数据共享的问题，编写起来更复杂。
	1.多进程
		1.Unix/Linux操作系统提供了一个fork()系统调用，它非常特殊。普通的函数调用，调用一次，返回一次，但是fork()调用一次，返回两次，因为操作系统自动把当前进程（称为父进程）复制了一份（称为子进程），
		然后，分别在父进程和子进程内返回。
		2.由于Windows没有fork调用,multiprocessing模块就是跨平台版本的多进程模块。
		3.multiprocessing模块提供了一个Process类来代表一个进程对象
	2.Pool
		1.如果要启动大量的子进程，可以用进程池的方式批量创建子进程
	3.子进程
		很多时候，子进程并不是自身，而是一个外部进程。我们创建了子进程后，还需要控制子进程的输入和输出。
		1.subprocess模块可以让我们非常方便地启动一个子进程，然后控制其输入和输出
		2.如果子进程还需要输入，则可以通过communicate()方法输入：
			import subprocess
			
			print('$ nslookup')
			p = subprocess.Popen(['nslookup'], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
			output, err = p.communicate(b'set q=mx\npython.org\nexit\n')
			print(output.decode('utf-8'))
			print('Exit code:', p.returncode)
	4.进程间通信
		1.Python的multiprocessing模块包装了底层的机制，提供了Queue、Pipes等多种方式来交换数据
		2.在Unix/Linux下，multiprocessing模块封装了fork()调用，使我们不需要关注fork()的细节。由于Windows没有fork调用，因此，multiprocessing需要“模拟”出fork的效果，
		父进程所有Python对象都必须通过pickle序列化再传到子进程去，所有，如果multiprocessing在Windows下调用失败了，要先考虑是不是pickle失败了。
	小结:
		1.在Unix/Linux下，可以使用fork()调用实现多进程。
		2.要实现跨平台的多进程，可以使用multiprocessing模块。
		3.进程间通信是通过Queue、Pipes等实现的。
	5.多线程：
		1.Python的标准库提供了两个模块：_thread和threading，_thread是低级模块，threading是高级模块，对_thread进行了封装。绝大多数情况下，我们只需要使用threading这个高级模块。
		2.启动一个线程就是把一个函数传入并创建Thread实例，然后调用start()开始执行
		3.由于任何进程默认就会启动一个线程，我们把该线程称为主线程，主线程又可以启动新的线程，Python的threading模块有个current_thread()函数，它永远返回当前线程的实例。
		4.主线程实例的名字叫MainThread，子线程的名字在创建时指定，我们用LoopThread命名子线程。名字仅仅在打印时用来显示，完全没有其他意义。
	6.Lock
		1.创建一个锁就是通过threading.Lock()来实现
		2.当多个线程同时执行lock.acquire()时，只有一个线程能成功地获取锁，然后继续执行代码，其他线程就继续等待直到获得锁为止。
		3.获得锁的线程用完后一定要释放锁，否则那些苦苦等待锁的线程将永远等待下去，成为死线程。所以我们用try...finally来确保锁一定会被释放
		4.锁的好处就是确保了某段关键代码只能由一个线程从头到尾完整地执行，坏处当然也很多，首先是阻止了多线程并发执行，包含锁的某段代码实际上只能以单线程模式执行，效率就大大地下降了。
		其次，由于可以存在多个锁，不同的线程持有不同的锁，并试图获取对方持有的锁时，可能会造成死锁，导致多个线程全部挂起，既不能执行，也无法结束，只能靠操作系统强制终止。
	7.多核CPU
		任何Python线程执行前，必须先获得GIL锁，然后，每执行100条字节码，解释器就自动释放GIL锁，让别的线程有机会执行。这个GIL全局锁实际上把所有线程的执行代码都给上了锁，所以，多线程在Python中只能交替执行，即使100个线程跑在100核CPU上，也只能用到1个核。
	小结：
		1.多线程编程，模型复杂，容易发生冲突，必须用锁加以隔离，同时，又要小心死锁的发生。
		2.Python解释器由于设计时有GIL全局锁，导致了多线程无法利用多核。多线程的并发在Python中就是一个美丽的梦。
	8.ThreadLocal
		1.ThreadLocal消除了对象在每层函数中的传递问题
		2.local_school = threading.local()
		3.ThreadLocal最常用的地方就是为每个线程绑定一个数据库连接，HTTP请求，用户身份信息等，这样一个线程的所有调用到的处理函数都可以非常方便地访问这些资源。
	小结：
		一个ThreadLocal变量虽然是全局变量，但每个线程都只能读写自己线程的独立副本，互不干扰。ThreadLocal解决了参数在一个线程中各个函数之间互相传递的问题。
	9.进程VS线程
		1.用多进程实现Master-Worker，主进程就是Master，其他进程就是Worker。稳定性高
		2.用多线程实现Master-Worker，主线程就是Master，其他线程就是Worker。稳定性差，一个子线程挂了程序整体也挂了
	10.分布式进程
		1.在Thread和Process中，应当优选Process，因为Process更稳定，而且，Process可以分布到多台机器上，而Thread最多只能分布到同一台机器的多个CPU上。
		2.multiprocessing模块不但支持多进程，其中managers子模块还支持把多进程分布到多台机器上。一个服务进程可以作为调度者，将任务分布到其他多个进程中，依靠网络通信。由于managers模块封装很好，不必了解网络通信的细节，就可以很容易地编写分布式多进程程序。
		3.Queue之所以能通过网络访问，就是通过QueueManager实现的。由于QueueManager管理的不止一个Queue，所以，要给每个Queue的网络调用接口起个名字，
			这是为了保证两台机器正常通信，不被其他机器恶意干扰。如果task_worker.py的authkey和task_master.py的authkey不一致，肯定连接不上。
	小结:
		1.Python的分布式进程接口简单，封装良好，适合需要把繁重任务分布到多台机器的环境下。
		2.Queue的作用是用来传递任务和接收结果，每个任务的描述数据量要尽量小
十二、正则表达式
	1.在正则表达式中，如果直接给出字符，就是精确匹配。用\d可以匹配一个数字，\w可以匹配一个字母或数字.
	2.'.'可以匹配任意字符
	3.要匹配变长的字符，在正则表达式中，用*表示任意个字符（包括0个），用+表示至少一个字符，用?表示0个或1个字符，用{n}表示n个字符，用{n,m}表示n-m个字符
	4.在正则表达式中，要用'\'转义
	5.要做更精确地匹配，可以用[]表示范围
	6.A|B可以匹配A或B，所以(P|p)ython可以匹配'Python'或者'python'
	7.^表示行的开头，^\d表示必须以数字开头。
	8.$表示行的结束，\d$表示必须以数字结束。
	9.切分字符串
		1.用正则表达式切分字符串比用固定的字符更灵活
		2.无法识别连续的空格，用正则表达式试试：
			>>> re.split(r'\s+', 'a b   c')
			['a', 'b', 'c']
		3.无论多少个空格都可以正常分割。加入,
			>>> re.split(r'[\s\,]+', 'a,b, c  d')
			['a', 'b', 'c', 'd']
		4.再加入;试试：
			>>> re.split(r'[\s\,\;]+', 'a,b;; c  d')
			['a', 'b', 'c', 'd']
	10.分组
		1.除了简单地判断是否匹配之外，正则表达式还有提取子串的强大功能。用()表示的就是要提取的分组（Group）。
		2.如果正则表达式中定义了组，就可以在Match对象上用group()方法提取出子串来
		3.注意到group(0)永远是原始字符串，group(1)、group(2)……表示第1、2、……个子串
	11.贪婪匹配
		1.需要特别指出的是，正则匹配默认是贪婪匹配，也就是匹配尽可能多的字符。举例如下，匹配出数字后面的0：
			>>> re.match(r'^(\d+)(0*)$', '102300').groups()
			('102300', '')
			由于\d+采用贪婪匹配，直接把后面的0全部匹配了，结果0*只能匹配空字符串了
			必须让\d+采用非贪婪匹配（也就是尽可能少匹配），才能把后面的0匹配出来，加个?就可以让\d+采用非贪婪匹配：
			>>> re.match(r'^(\d+?)(0*)$', '102300').groups()
			('1023', '00')
	12.编译
		1.当我们在Python中使用正则表达式时，re模块内部会干两件事情：
			1.编译正则表达式，如果正则表达式的字符串本身不合法，会报错；
			2.用编译后的正则表达式去匹配字符串。
		2.编译后生成Regular Expression对象，由于该对象自己包含了正则表达式，所以调用对应的方法时不用给出正则字符串。
	小结：正则表达式非常强大，要在短短的一节里讲完是不可能的。要讲清楚正则的所有内容，可以写一本厚厚的书了。如果你经常遇到正则表达式的问题，你可能需要一本正则表达式的参考书。
十三、常用内建模块
	1.datetime
		1.datetime是Python处理日期和时间的标准库。
		2.获取当前日期和时间:datetime.now()返回当前日期和时间，其类型是datetime
		3.获取指定日期和时间:
			>>> from datetime import datetime
			>>> dt = datetime(2015, 4, 19, 12, 20) # 用指定日期时间创建datetime
			>>> print(dt)
			2015-04-19 12:20:00
		4.datetime转换为timestamp,也就是转化为从1970.1.1 0:0:0开始到现在为多少秒
			>>> from datetime import datetime
			>>> dt = datetime(2015, 4, 19, 12, 20) # 用指定日期时间创建datetime
			>>> dt.timestamp() # 把datetime转换为timestamp
			1429417200.0
			Python的timestamp是一个浮点数。如果有小数位，小数位表示毫秒数。
		5.timestamp转换为datetime
			要把timestamp转换为datetime，使用datetime提供的fromtimestamp()方法：
			>>> from datetime import datetime
			>>> t = 1429417200.0
			>>> print(datetime.fromtimestamp(t))
			2015-04-19 12:20:00
		6.str转换为datetime
			转换方法是通过datetime.strptime()实现，需要一个日期和时间的格式化字符串：
			>>> from datetime import datetime
			>>> cday = datetime.strptime('2015-6-1 18:19:59', '%Y-%m-%d %H:%M:%S')
			>>> print(cday)
			2015-06-01 18:19:59
			注意转换后的datetime是没有时区信息的
		7.datetime转换为str
			如果已经有了datetime对象，要把它格式化为字符串显示给用户，就需要转换为str，转换方法是通过strftime()实现的，
			同样需要一个日期和时间的格式化字符串：
			>>> from datetime import datetime
			>>> now = datetime.now()
			>>> print(now.strftime('%a, %b %d %H:%M'))
			Mon, May 05 16:28
		8.datetime加减
			对日期和时间进行加减实际上就是把datetime往后或往前计算，得到新的datetime。
			加减可以直接用+和-运算符，不过需要导入timedelta这个类
			>>> from datetime import datetime, timedelta
			>>> now = datetime.now()
			>>> now
			datetime.datetime(2015, 5, 18, 16, 57, 3, 540997)
			>>> now + timedelta(hours=10)
			datetime.datetime(2015, 5, 19, 2, 57, 3, 540997)
			>>> now - timedelta(days=1)
			datetime.datetime(2015, 5, 17, 16, 57, 3, 540997)
			>>> now + timedelta(days=2, hours=12)
			datetime.datetime(2015, 5, 21, 4, 57, 3, 540997)
			使用timedelta你可以很容易地算出前几天和后几天的时刻
		9.本地时间转换为UTC时间
			1.本地时间是指系统设定时区的时间，例如北京时间是UTC+8:00时区的时间，而UTC时间指UTC+0:00时区的时间
			2.一个datetime类型有一个时区属性tzinfo，但是默认为None，所以无法区分这个datetime到底是哪个时区，除非强行给datetime设置一个时区
			>>> from datetime import datetime, timedelta, timezone
			>>> tz_utc_8 = timezone(timedelta(hours=8)) # 创建时区UTC+8:00
			>>> now = datetime.now()
			>>> now
			datetime.datetime(2015, 5, 18, 17, 2, 10, 871012)
			>>> dt = now.replace(tzinfo=tz_utc_8) # 强制设置为UTC+8:00
			>>> dt
			datetime.datetime(2015, 5, 18, 17, 2, 10, 871012, tzinfo=datetime.timezone(datetime.timedelta(0, 28800)))
		如果系统时区恰好是UTC+8:00，那么上述代码就是正确的，否则，不能强制设置为UTC+8:00时区。
		10.时区转换
			1.我们可以先通过utcnow()拿到当前的UTC时间，再转换为任意时区的时间：
			# 拿到UTC时间，并强制设置时区为UTC+0:00:
			>>> utc_dt = datetime.utcnow().replace(tzinfo=timezone.utc)
			>>> print(utc_dt)
			2015-05-18 09:05:12.377316+00:00
			# astimezone()将转换时区为北京时间:
			>>> bj_dt = utc_dt.astimezone(timezone(timedelta(hours=8)))
			>>> print(bj_dt)
			2015-05-18 17:05:12.377316+08:00
			# astimezone()将转换时区为东京时间:
			>>> tokyo_dt = utc_dt.astimezone(timezone(timedelta(hours=9)))
			>>> print(tokyo_dt)
			2015-05-18 18:05:12.377316+09:00
			# astimezone()将bj_dt转换时区为东京时间:
			>>> tokyo_dt2 = bj_dt.astimezone(timezone(timedelta(hours=9)))
			>>> print(tokyo_dt2)
			2015-05-18 18:05:12.377316+09:00
		时区转换的关键在于，拿到一个datetime时，要获知其正确的时区，然后强制设置时区，作为基准时间。
		利用带时区的datetime，通过astimezone()方法，可以转换到任意时区。
		不是必须从UTC+0:00时区转换到其他时区，任何带时区的datetime都可以正确转换，例如上述bj_dt到tokyo_dt的转换。
	小结：
		1.datetime表示的时间需要时区信息才能确定一个特定的时间，否则只能视为本地时间。
		2.如果要存储datetime，最佳方法是将其转换为timestamp再存储，因为timestamp的值与时区完全无关。
	2.collections
		1.collections是Python内建的一个集合模块，提供了许多有用的集合类。
		2.namedtuple：1.namedtuple是一个函数，它用来创建一个自定义的tuple对象，并且规定了tuple元素的个数，并可以用属性而不是索引来引用tuple的某个元素。
					  2.类似的，如果要用坐标和半径表示一个圆，也可以用namedtuple定义：
						# namedtuple('名称', [属性list]):
						Circle = namedtuple('Circle', ['x', 'y', 'r'])
		3.deque
			1.使用list存储数据时，按索引访问元素很快，但是插入和删除元素就很慢了，因为list是线性存储，数据量大的时候，插入和删除效率很低。
			2.deque是为了高效实现插入和删除操作的双向列表，适合用于队列和栈：
				>>> from collections import deque
				>>> q = deque(['a', 'b', 'c'])
				>>> q.append('x')
				>>> q.appendleft('y')
				>>> q
				deque(['y', 'a', 'b', 'c', 'x'])
			3.deque除了实现list的append()和pop()外，还支持appendleft()和popleft()，这样就可以非常高效地往头部添加或删除元素。
		4.defaultdict
			1.使用dict时，如果引用的Key不存在，就会抛出KeyError。如果希望key不存在时，返回一个默认值，就可以用defaultdict：
				>>> from collections import defaultdict
				>>> dd = defaultdict(lambda: 'N/A')
				>>> dd['key1'] = 'abc'
				>>> dd['key1'] # key1存在
				'abc'
				>>> dd['key2'] # key2不存在，返回默认值
				'N/A'
			2.注意默认值是调用函数返回的，而函数在创建defaultdict对象时传入。
			3.除了在Key不存在时返回默认值，defaultdict的其他行为跟dict是完全一样的。
		5.OrderedDict
			1.使用dict时，Key是无序的。在对dict做迭代时，我们无法确定Key的顺序。如果要保持Key的顺序，可以用OrderedDict：
				>>> from collections import OrderedDict
				>>> d = dict([('a', 1), ('b', 2), ('c', 3)])
				>>> d # dict的Key是无序的
				{'a': 1, 'c': 3, 'b': 2}
				>>> od = OrderedDict([('a', 1), ('b', 2), ('c', 3)])
				>>> od # OrderedDict的Key是有序的
				OrderedDict([('a', 1), ('b', 2), ('c', 3)])
			2.OrderedDict的Key会按照插入的顺序排列，不是Key本身排序
			3.OrderedDict可以实现一个FIFO（先进先出）的dict，当容量超出限制时，先删除最早添加的Key
		6.Counter
			1.Counter是一个简单的计数器，例如，统计字符出现的个数：
			>>> from collections import Counter
			>>> c = Counter()
			>>> for ch in 'programming':
			...     c[ch] = c[ch] + 1
			...
			>>> c
			Counter({'g': 2, 'm': 2, 'r': 2, 'a': 1, 'i': 1, 'o': 1, 'n': 1, 'p': 1})
			2.Counter实际上也是dict的一个子类，上面的结果可以看出，字符'g'、'm'、'r'各出现了两次，其他字符各出现了一次。
	小结：collections模块提供了一些有用的集合类，可以根据需要选用。
	3.base64
		1.Base64是一种用64个字符来表示任意二进制数据的方法。
		2.Base64编码会把3字节的二进制数据编码为4字节的文本数据，长度增加33%，好处是编码后的文本数据可以在邮件正文、网页等直接显示。
		3.Python内置的base64可以直接进行base64的编解码
		4.由于标准的Base64编码后可能出现字符+和/，在URL中就不能直接作为参数，所以又有一种"url safe"的base64编码，其实就是把字符+和/分别变成-和_
	小结：Base64是一种任意二进制到文本字符串的编码方法，常用于在URL、Cookie、网页中传输少量二进制数据。
	4.struct
		1.ython没有专门处理字节的数据类型。但由于b'str'可以表示字节，所以，字节数组＝二进制str。
		2.struct模块来解决bytes和其他二进制数据类型的转换
		3.struct的pack函数把任意数据类型变成bytes:
			>>> import struct
			>>> struct.pack('>I', 10240099)
			b'\x00\x9c@c'
			1.pack的第一个参数是处理指令，'>I'的意思是：
			>表示字节顺序是big-endian，也就是网络序，I表示4字节无符号整数。
			后面的参数个数要和处理指令一致。
			2.unpack把bytes变成相应的数据类型：
				>>> struct.unpack('>IH', b'\xf0\xf0\xf0\xf0\x80\x80')
				(4042322160, 32896)
				2.根据>IH的说明，后面的bytes依次变为I：4字节无符号整数和H：2字节无符号整数。
	5.hashlib
		1.Python的hashlib提供了常见的摘要算法，如MD5，SHA1等等。
		2.以常见的摘要算法MD5为例，计算出一个字符串的MD5值:
			import hashlib
			md5 = hashlib.md5()
			md5.update('how to use md5 in python hashlib?'.encode('utf-8'))
			print(md5.hexdigest())
		3.由于常用口令的MD5值很容易被计算出来，所以，要确保存储的用户口令不是那些已经被计算出来的常用口令的MD5，
		这一方法通过对原始口令加一个复杂字符串来实现，俗称“加盐”：
		def calc_md5(password):
			return get_md5(password + 'the-Salt')
	小结：摘要算法在很多地方都有广泛的应用。要注意摘要算法不是加密算法，不能用于加密（因为无法通过摘要反推明文），
		只能用于防篡改，但是它的单向计算特性决定了可以在不存储明文口令的情况下验证用户口令。
	6.itertools
		1.Python的内建模块itertools提供了非常有用的用于操作迭代对象的函数。
		2.count()会创建一个无限的迭代器
		3.cycle()会把传入的一个序列无限重复下去
		4.repeat()负责把一个元素无限重复下去，不过如果提供第二个参数就可以限定重复次数
		5.无限序列只有在for迭代时才会无限地迭代下去，如果只是创建了一个迭代对象，它不会事先把无限个元素生成出来，事实上也不可能在内存中创建无限多个元素。
		6.无限序列虽然可以无限迭代下去，但是通常我们会通过takewhile()等函数根据条件判断来截取出一个有限的序列：
			>>> natuals = itertools.count(1)
			>>> ns = itertools.takewhile(lambda x: x <= 10, natuals)
			>>> list(ns)
			[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
		7.chain()可以把一组迭代对象串联起来，形成一个更大的迭代器：
			>>> for c in itertools.chain('ABC', 'XYZ'):
			...     print(c)
			# 迭代效果：'A' 'B' 'C' 'X' 'Y' 'Z'
		8.groupby()把迭代器中相邻的重复元素挑出来放在一起
	小结：itertools模块提供的全部是处理迭代功能的函数，它们的返回值不是list，而是Iterator，只有用for循环迭代的时候才真正计算。
	7.contextlib
		1.在Python中，读写文件这样的资源要特别注意，必须在使用完毕后正确关闭它们。正确关闭文件资源的一个方法是使用try...finally
		2.写try...finally非常繁琐。Python的with语句允许我们非常方便地使用资源，而不必担心资源没有关闭
		3.并不是只有open()函数返回的fp对象才能使用with语句。实际上，任何对象，只要正确实现了上下文管理，就可以用于with语句
		4.实现上下文管理是通过__enter__和__exit__这两个方法实现的，这样我们就可以把自己写的资源对象用于with语句
		5.@contextmanager
			1.编写__enter__和__exit__仍然很繁琐，因此Python的标准库contextlib提供了更简单的写法
			2.@contextmanager这个decorator接受一个generator，用yield语句把with ... as var把变量输出出去，然后，with语句就可以正常地工作了
			3.很多时候，我们希望在某段代码执行前后自动执行特定代码，也可以用@contextmanager实现。例如：
				@contextmanager
				def tag(name):
					print("<%s>" % name)
					yield
					print("</%s>" % name)

				with tag("h1"):
					print("hello")
					print("world")
		6.@closing
			1.如果一个对象没有实现上下文，我们就不能把它用于with语句。这个时候，可以用closing()来把该对象变为上下文对象。
			2.例如，用with语句使用urlopen()：
				from contextlib import closing
				from urllib.request import urlopen

				with closing(urlopen('https://www.python.org')) as page:
					for line in page:
						print(line)
			3.closing也是一个经过@contextmanager装饰的generator，这个generator编写起来其实非常简单：
				@contextmanager
				def closing(thing):
					try:
						yield thing
					finally:
						thing.close()
	8.XML
		1.XML虽然比JSON复杂，在Web中应用也不如以前多了，不过仍有很多地方在用，所以，有必要了解如何操作XML。
		2.DOM vs SAX：
			1.操作XML有两种方法：DOM和SAX。
			2.DOM会把整个XML读入内存，解析为树，因此占用内存大，解析慢，优点是可以任意遍历树的节点。
			3.SAX是流模式，边读边解析，占用内存小，解析快，缺点是我们需要自己处理事件。
		3.1在Python中使用SAX解析XML非常简洁，通常我们关心的事件是start_element，end_element和char_data，准备好这3个函数，然后就可以解析xml了
		3.2需要注意的是读取一大段字符串时，CharacterDataHandler可能被多次调用，所以需要自己保存起来，在EndElementHandler里面再合并。
		4.除了解析XML外，如何生成XML呢？99%的情况下需要生成的XML结构都是非常简单的，因此，最简单也是最有效的生成XML的方法是拼接字符串：
			L = []
			L.append(r'<?xml version="1.0"?>')
			L.append(r'<root>')
			L.append(encode('some & data'))
			L.append(r'</root>')
			return ''.join(L)
	9.HTMLParser
		1.如果我们要编写一个搜索引擎，第一步是用爬虫把目标网站的页面抓下来，第二步就是解析该HTML页面，看看里面的内容到底是新闻、图片还是视频。
		2.HTML本质上是XML的子集，但是HTML的语法没有XML那么严格，所以不能用标准的DOM或SAX来解析HTML。
		3.好在Python提供了HTMLParser来非常方便地解析HTML，只需简单几行代码
	10.urllib
		1.urllib提供了一系列用于操作URL的功能。
		2.Get,urllib的request模块可以非常方便地抓取URL内容，也就是发送一个GET请求到指定的页面，然后返回HTTP的响应
		3.如果我们要想模拟浏览器发送GET请求，就需要使用Request对象，通过往Request对象添加HTTP头，我们就可以把请求伪装成浏览器。
		4.post:如果要以POST发送一个请求，只需要把参数data以bytes形式传入
		5.我们模拟一个微博登录，先读取登录的邮箱和口令，然后按照weibo.cn的登录页的格式以username=xxx&password=xxx的编码传入
		6.Handler:如果还需要更复杂的控制，比如通过一个Proxy去访问网站，我们需要利用ProxyHandler来处理，示例代码如下：
			proxy_handler = urllib.request.ProxyHandler({'http': 'http://www.example.com:3128/'})
			proxy_auth_handler = urllib.request.ProxyBasicAuthHandler()
			proxy_auth_handler.add_password('realm', 'host', 'username', 'password')
			opener = urllib.request.build_opener(proxy_handler, proxy_auth_handler)
			with opener.open('http://www.example.com/login.html') as f:
				pass
	小结:urllib提供的功能就是利用程序去执行各种HTTP请求。如果要模拟浏览器完成特定功能，需要把请求伪装成浏览器。伪装的方法是先监控浏览器发出的请求，再根据浏览器的请求头来伪装，User-Agent头就是用来标识浏览器的。
十四、常用的三方模块：
	1.PIL
		1.操作图像:
			from PIL import Image

			# 打开一个jpg图像文件，注意是当前路径:
			im = Image.open('test.jpg')
			# 获得图像尺寸:
			w, h = im.size
			print('Original image size: %sx%s' % (w, h))
			# 缩放到50%:
			im.thumbnail((w//2, h//2))
			print('Resize image to: %sx%s' % (w//2, h//2))
			# 把缩放后的图像用jpeg格式保存:
			im.save('thumbnail.jpg', 'jpeg')
		2.其他功能如切片、旋转、滤镜、输出文字、调色板等一应俱全。比如，模糊效果也只需几行代码：
			from PIL import Image, ImageFilter

			# 打开一个jpg图像文件，注意是当前路径:
			im = Image.open('test.jpg')
			# 应用模糊滤镜:
			im2 = im.filter(ImageFilter.BLUR)
			im2.save('blur.jpg', 'jpeg')
		3.PIL的ImageDraw提供了一系列绘图方法，让我们可以直接绘图。比如要生成字母验证码图片
		4.PIL无法定位到字体文件的位置，可以根据操作系统提供绝对路径，比如：
			'/Library/Fonts/Arial.ttf'
	小结:PIL提供了操作图像的强大功能，可以通过简单的代码完成复杂的图像处理。
十五、virtualenv
	1.第一步，创建目录
	2.第二步，创建一个独立的Python运行环境，命名为venv
	3.命令virtualenv就可以创建一个独立的Python运行环境，我们还加上了参数--no-site-packages，这样，已经安装到系统Python环境中的所有第三方包都不会复制过来，
	这样，我们就得到了一个不带任何第三方包的“干净”的Python运行环境。
	4.在venv环境下，用pip安装的包都被安装到venv这个环境下，系统Python环境不受任何影响。也就是说，venv环境是专门针对myproject这个应用创建的。
	5.退出当前的venv环境，使用deactivate命令
	小结：virtualenv为应用提供了隔离的Python运行环境，解决了不同应用间多版本的冲突问题。
十六、图形界面
	1.Tkinter
		1.第一步是导入Tkinter包的所有内容
		2.第二步是从Frame派生一个Application类，这是所有Widget的父容器
		3.在GUI中，每个Button、Label、输入框等，都是一个Widget。Frame则是可以容纳其他Widget的Widget，所有的Widget组合起来就是一棵树。
		4.pack()方法把Widget加入到父容器中，并实现布局。pack()是最简单的布局，grid()可以实现更复杂的布局。
		5.在createWidgets()方法中，我们创建一个Label和一个Button，当Button被点击时，触发self.quit()使程序退出
		6.第三步，实例化Application，并启动消息循环
	小结：Python内置的Tkinter可以满足基本的GUI程序的要求，如果是非常复杂的GUI程序，建议用操作系统原生支持的语言和库来编写。
十七、网路编程
	1.网络变成就是两个进程之间在进行通讯
	2.TCP/IP：TCP协议负责在两台计算机之间建立可靠连接，保证数据包按顺序到达。TCP协议会通过握手建立连接，然后，对每个IP包编号，确保对方按顺序收到，如果包丢掉了，就自动重发。
	3.TCP编程
		1.Socket是网络编程的一个抽象概念。通常我们用一个Socket表示“打开了一个网络链接”，而打开一个Socket需要知道目标计算机的IP地址和端口号，再指定协议类型即可。
		2.客户端
			1.大多数连接都是可靠的TCP连接。创建TCP连接时，主动发起连接的叫客户端，被动响应连接的叫服务器。
		2.服务器
			1.和客户端编程相比，服务器编程就要复杂一些。
			2.服务器进程首先要绑定一个端口并监听来自其他客户端的连接。如果某个客户端连接过来了，服务器就与该客户端建立Socket连接，随后的通信就靠这个Socket连接了。
			3.服务器会打开固定端口（比如80）监听，每来一个客户端连接，就创建该Socket连接。
			4.一个Socket依赖4项：服务器地址、服务器端口、客户端地址、客户端端口来唯一确定一个Socket。
	小结：
		1.用TCP协议进行Socket编程在Python中十分简单，对于客户端，要主动连接服务器的IP和指定端口，对于服务器，要首先监听指定端口，然后，对每一个新的连接，创建一个线程或进程来处理。通常，服务器程序会无限运行下去。
		2.同一个端口，被一个Socket绑定了以后，就不能被别的Socket绑定了。
	4.UDP編程
		1.TCP是建立可靠连接，并且通信双方都可以以流的形式发送数据。相对TCP，UDP则是面向无连接的协议。
		2.使用UDP协议时，不需要建立连接，只需要知道对方的IP地址和端口号，就可以直接发数据包。但是，能不能到达就不知道了。
		3.和TCP类似，使用UDP的通信双方也分为客户端和服务器。服务器首先需要绑定端口：
	小结：UDP的使用与TCP类似，但是不需要建立连接。此外，服务器绑定UDP端口和TCP端口互不冲突，也就是说，UDP的9999端口与TCP的9999端口可以各自绑定。
十八、电子邮件
	1.Email的历史比Web还要久远，直到现在，Email也是互联网上应用非常广泛的服务。
	2.封电子邮件的旅程就是：发件人 -> MUA -> MTA -> MTA -> 若干个MTA -> MDA <- MUA <- 收件人
	3.有了上述基本概念，要编写程序来发送和接收邮件，本质上就是：
		1.编写MUA把邮件发到MTA；
		2.编写MUA从MDA上收邮件。
	4.发邮件时，MUA和MTA使用的协议就是SMTP：Simple Mail Transfer Protocol，后面的MTA到另一个MTA也是用SMTP协议。
	5.收邮件时，MUA和MDA使用的协议有两种：POP：Post Office Protocol，目前版本是3，俗称POP3；IMAP：Internet Message Access Protocol，
	目前版本是4，优点是不但能取邮件，还可以直接操作MDA上存储的邮件，比如从收件箱移到垃圾箱，等等。
	6.SMTP发送邮件
		1.SMTP是发送邮件的协议，Python内置对SMTP的支持，可以发送纯文本邮件、HTML邮件以及带附件的邮件。
		2.Python对SMTP支持有smtplib和email两个模块，email负责构造邮件，smtplib负责发送邮件。
		3.set_debuglevel(1)就可以打印出和SMTP服务器交互的所有信息。
		4.login()方法用来登录SMTP服务器，sendmail()方法就是发邮件，由于可以一次发给多个人，所以传入一个list，邮件正文是一个str，as_string()把MIMEText对象变成str。
		5.发送HTML邮件
			1.在构造MIMEText对象时，把HTML字符串传进去，再把第二个参数由plain变为html就可以了：
		6.发送附件
			1.构造一个MIMEMultipart对象代表邮件本身，然后往里面加上一个MIMEText作为邮件正文，再继续往里面加上表示附件的MIMEBase对象即可
		7.发送图片:
			1.我们只需按照发送附件的方式，先把邮件作为附件添加进去，然后，在HTML中通过引用src="cid:0"就可以把附件作为图片嵌入了。如果有多个图片，给它们依次编号，然后引用不同的cid:x即可。
			2.代码加入MIMEMultipart的MIMEText从plain改为html，然后在适当的位置引用图片
		8.加密SMTP
			1.使用标准的25端口连接SMTP服务器时，使用的是明文传输，发送邮件的整个过程可能会被窃听。要更安全地发送邮件，可以加密SMTP会话，实际上就是先创建SSL安全连接，然后再使用SMTP协议发送邮件。
			2.只需要在创建SMTP对象后，立刻调用starttls()方法，就创建了安全连接。后面的代码和前面的发送邮件代码完全一样。
	小结：构造一个邮件对象就是一个Messag对象，如果构造一个MIMEText对象，就表示一个文本邮件对象，如果构造一个MIMEImage对象，就表示一个作为附件的图片，要把多个对象组合起来，就用MIMEMultipart对象，
		而MIMEBase可以表示任何对象。它们的继承关系如下：
			Message
			+- MIMEBase
			   +- MIMEMultipart
			   +- MIMENonMultipart
				  +- MIMEMessage
				  +- MIMEText
				  +- MIMEImage
	7.POP3收取邮件
		1.收取邮件就是编写一个MUA作为客户端，从MDA把邮件获取到用户的电脑或者手机上。
		2.python内置一个poplib模块，实现了POP3协议，可以直接用来收邮件。
		3.要把POP3收取的文本变成可以阅读的邮件，还需要用email模块提供的各种类来解析原始文本，变成可阅读的邮件对象。
		4.收取邮件分两步：
			1.第一步：用poplib把邮件的原始文本下载到本地；
			2.第二部：用email解析原始文本，还原为邮件对象。
		5.通过POP3下载邮件:，要获取所有邮件，只需要循环使用retr()把每一封邮件内容拿到即可。
		6.解析邮件：
			1. 我们要递归地打印出Message对象的层次结构
			2.邮件的Subject或者Email中包含的名字都是经过编码后的str，要正常显示，就必须decode
			3.decode_header()返回一个list，因为像Cc、Bcc这样的字段可能包含多个邮件地址，所以解析出来的会有多个元素。
	小结：  用Python的poplib模块收取邮件分两步：第一步是用POP3协议把邮件获取到本地，
			第二步是用email模块把原始邮件解析为Message对象，然后，用适当的形式把邮件内容展示给用户即可。
十九、访问数据库
	1.使用SQLite
		1.要操作关系数据库，首先需要连接到数据库，一个数据库连接称为Connection
		2.连接到数据库后，需要打开游标，称之为Cursor，通过Cursor执行SQL语句，然后，获得执行结果
		3.使用Python的DB-API时，只要搞清楚Connection和Cursor对象，打开后一定记得关闭，就可以放心地使用。
		4.使用Cursor对象执行insert，update，delete语句时，执行结果由rowcount返回影响的行数，就可以拿到执行结果。
		5.使用Cursor对象执行select语句时，通过featchall()可以拿到结果集。结果集是一个list，每个元素都是一个tuple，对应一行记录。
		6.如果SQL语句带有参数，那么需要把参数按照位置传递给execute()方法，有几个?占位符就必须对应几个参数，例如：
			cursor.execute('select * from user where name=? and pwd=?', ('abc', 'password'))
	小结：	1.在Python中操作数据库时，要先导入数据库对应的驱动，然后，通过Connection对象和Cursor对象操作数据。
			2.要确保打开的Connection对象和Cursor对象都正确地被关闭，否则，资源就会泄露。
			3.建议使用try..exept..finally方法
	2.使用MySQL
		1.安装MySQL驱动
			pip install mysql-connector
		2.由于Python的DB-API定义都是通用的，所以，操作MySQL的数据库代码和SQLite类似。
	小结：1.执行INSERT等操作后要调用commit()提交事务；
		  2.MySQL的SQL占位符是%s。
	3.使用SQLalchemy
		1.数据库表是一个二维表，包含多行多列。把一个表的内容用Python的数据结构表示出来的话，
			可以用一个list表示多行，list的每一个元素是tuple，表示一行记录，
		2.但是用tuple表示一行很难看出表的结构。如果把一个tuple用class实例来表示，就可以更容易地看出表的结构来
		3.这就是传说中的ORM技术：Object-Relational Mapping，把关系数据库的表结构映射到对象上
		4.第一步，导入SQLAlchemy，并初始化DBSession
		5.如果有多个表，就继续定义其他class
		6.由于有了ORM，我们向数据库表中添加一行记录，可以视为添加一个User对象
		7.可见，关键是获取session，然后把对象添加到session，最后提交并关闭。DBSession对象可视为当前数据库连接。
		8.由于关系数据库的多个表还可以用外键实现一对多、多对多等关联，相应地，ORM框架也可以提供两个对象之间的一对多、多对多等功能。
	小结：1.ORM框架的作用就是把数据库表的一行记录与一个对象互相做自动转换。
		  2.正确使用ORM的前提是了解关系数据库的原理。
二十、Web开发
	1.HTTP协议简介
		1.HTML是一种用来定义网页的文本，会HTML，就可以编写网页；
		2.HTML是一种用来定义网页的文本，会HTML，就可以编写网页；
	2.HTTP请求
		1.步骤1：浏览器首先向服务器发送HTTP请求，请求包括：
			1.方法：GET还是POST，GET仅请求资源，POST会附带用户数据；
			2.路径：/full/url/path；
			3.域名：由Host头指定：Host: www.sina.com.cn
			4.以及其他相关的Header；
			5.如果是POST，那么请求还包括一个Body，包含用户数据。
		2.步骤2：服务器向浏览器返回HTTP响应，响应包括：
			1.响应代码：200表示成功，3xx表示重定向，4xx表示客户端发送的请求有错误，5xx表示服务器端处理时发生了错误；
			2.响应类型：由Content-Type指定；
			3.以及其他相关的Header；
			4.通常服务器的HTTP响应会携带内容，也就是有一个Body，包含响应的内容，网页的HTML源码就在Body中。
		3.步骤3：如果浏览器还需要继续向服务器请求其他资源，比如图片，就再次发出HTTP请求，重复步骤1、2。
	3.HTTP格式
		1.每个HTTP请求和响应都遵循相同的格式，一个HTTP包含Header和Body两部分，其中Body是可选的。
		2.HTTP协议是一种文本协议，所以，它的格式也非常简单。HTTP GET请求的格式：
			GET /path HTTP/1.1
			Header1: Value1
			Header2: Value2
			Header3: Value3
		3.每个Header一行一个，换行符是\r\n。
		4.HTTP POST请求的格式：
			POST /path HTTP/1.1
			Header1: Value1
			Header2: Value2
			Header3: Value3

			body data goes here..
		5.当遇到连续两个\r\n时，Header部分结束，后面的数据全部是Body。
		6.HTTP响应的格式：
			200 OK
			Header1: Value1
			Header2: Value2
			Header3: Value3

			body data goes here...
		7.HTTP响应如果包含body，也是通过\r\n\r\n来分隔的。请再次注意，Body的数据类型由Content-Type头来确定，如果是网页，Body就是文本，如果是图片，Body就是图片的二进制数据。
		8.当存在Content-Encoding时，Body数据是被压缩的，最常见的压缩方式是gzip，所以，看到Content-Encoding: gzip时，需要将Body数据先解压缩，才能得到真正的数据。
			压缩的目的在于减少Body的大小，加快网络传输。
	4.HTML简介
		1.HTML文档就是一系列的Tag组成，最外层的Tag是<html>。
	5.CSS简介
		1.CSS是Cascading Style Sheets（层叠样式表）的简称，CSS用来控制HTML里的所有元素如何展现，比如，给标题元素<h1>加一个样式，变成48号字体，灰色，带阴影：
	6.JavaScript
		1.JavaScript是为了让HTML具有交互性而作为脚本语言添加的，JavaScript既可以内嵌到HTML中，也可以从外部链接到HTML中。
		2.如果我们希望当用户点击标题时把标题变成红色，就必须通过JavaScript来实现
	小结：HTML定义了页面的内容，CSS来控制页面元素的样式，而JavaScript负责页面的交互逻辑。
	7.WSGI接口
		1.Web应用的本质就是：
			1.浏览器发送一个HTTP请求；
			2.服务器收到请求，生成一个HTML文档；
			3.服务器把HTML文档作为HTTP响应的Body发送给浏览器；
			4.浏览器收到HTTP响应，从HTTP Body取出HTML文档并显示。
		2.让我们专心用Python编写Web业务，这个接口就是WSGI：Web Server Gateway Interface。
		3.WSGI接口定义非常简单，它只要求Web开发者实现一个函数，就可以响应HTTP请求。我们来看一个最简单的Web版本的“Hello, web!”：
			def application(environ, start_response):
				start_response('200 OK', [('Content-Type', 'text/html')])
				return [b'<h1>Hello, web!</h1>']
			1.上面的application()函数就是符合WSGI标准的一个HTTP处理函数，它接收两个参数：
				1.environ：一个包含所有HTTP请求信息的dict对象；
				2.start_response：一个发送HTTP响应的函数。
			2.在application()函数中，调用：
				start_response('200 OK', [('Content-Type', 'text/html')])
			3.就发送了HTTP响应的Header，注意Header只能发送一次，也就是只能调用一次start_response()函数。
			4.start_response()函数接收两个参数，一个是HTTP响应码，一个是一组list表示的HTTP Header，每个Header用一个包含两个str的tuple表示。
			5.通常情况下，都应该把Content-Type头发送给浏览器。其他很多常用的HTTP Header也应该发送。
			6.然后，函数的返回值b'<h1>Hello, web!</h1>'将作为HTTP响应的Body发送给浏览器。
		4.Python内置了一个WSGI服务器，这个模块叫wsgiref，它是用纯Python编写的WSGI服务器的参考实现。
			所谓“参考实现”是指该实现完全符合WSGI标准，但是不考虑任何运行效率，仅供开发和测试使用。
	8.运行WSGI服务
		1.先编写hello.py，实现Web应用程序的WSGI处理函数
		2.再编写一个server.py，负责启动WSGI服务器，加载application()函数
	小结：
		1.无论多么复杂的Web应用程序，入口都是一个WSGI处理函数。HTTP请求的所有输入信息都可以通过environ获得，HTTP响应的输出都可以通过start_response()加上函数返回值作为Body。
		2.复杂的Web应用程序，光靠一个WSGI函数来处理还是太底层了，我们需要在WSGI之上再抽象出Web框架，进一步简化Web开发。
	9.使用web框架
		1.每一个URL可以对应GET和POST请求，当然还有PUT、DELETE等请求，但是我们通常只考虑最常见的GET和POST请求。
		2.一个最简单的想法是从environ变量里取出HTTP请求的信息，然后逐个判断，但是这样代码肯定无法维护
		3.选择一个比较流行的Web框架——Flask来使用
		4.然后写一个app.py，处理3个URL，分别是：
			1.GET /：首页，返回Home；
			2.GET /signin：登录页，显示登录表单；
			3.POST /signin：处理登录表单，显示登录结果。
		5.运行python app.py，Flask自带的Server在端口5000上监听：
		6.实际的Web App应该拿到用户名和口令后，去数据库查询再比对，来判断用户是否能登录成功。
		7.除了Flask，常见的Python Web框架还有：
			1.Django：全能型Web框架；
			2.web.py：一个小巧的Web框架
			3.Bottle：和Flask类似的Web框架；
			4.Tornado：Facebook的开源异步Web框架。
	小结：1.有了Web框架，我们在编写Web应用时，注意力就从WSGI处理函数转移到URL+对应的处理函数，这样，编写Web App就更加简单了。
		  2.在编写URL处理函数时，除了配置URL外，从HTTP请求拿到用户数据也是非常重要的。Web框架都提供了自己的API来实现这些功能。Flask通过request.form['name']来获取表单的内容。
	10.使用模板
		1.由于在Python代码里拼字符串是不现实的，所以，模板技术出现了
		2.使用模板，我们需要预先准备一个HTML文档，这个HTML文档不是普通的HTML，而是嵌入了一些变量和指令，然后，根据我们传入的数据，替换后，得到最终的HTML，发送给用户
		3.这就是传说中的MVC：Model-View-Controller，中文名“模型-视图-控制器”。
		4.Python处理URL的函数就是C：Controller，Controller负责业务逻辑，比如检查用户名是否存在，取出用户信息等等；
		5.包含变量{{ name }}的模板就是V：View，View负责显示逻辑，通过简单地替换一些变量，View最终输出的就是用户看到的HTML。
		6.Flask通过render_template()函数来实现模板的渲染。和Web框架类似，Python的模板也有很多种。Flask默认支持的模板是jinja2
		7.最后，一定要把模板放到正确的templates目录下，templates和app.py在同级目录下
		8.通过MVC，我们在Python代码中处理M：Model和C：Controller，而V：View是通过模板处理的，这样，我们就成功地把Python代码和HTML代码最大限度地分离了。
		9.使用模板的另一大好处是，模板改起来很方便，而且，改完保存后，刷新浏览器就能看到最新的效果，
		10.在Jinja2模板中，我们用{{ name }}表示一个需要替换的变量。很多时候，还需要循环、条件判断等指令语句，在Jinja2中，用{% ... %}表示指令。
		11.比如循环输出页码：
			{% for i in page_list %}
				<a href="/page/{{ i }}">{{ i }}</a>
			{% endfor %}
		12.除了Jinja2，常见的模板还有：
			1.Mako：用<% ... %>和${xxx}的一个模板；
			2.Cheetah：也是用<% ... %>和${xxx}的一个模板；
			3.Django：Django是一站式框架，内置一个用{% ... %}和{{ xxx }}的模板。
	小结：有了MVC，我们就分离了Python代码和HTML代码。HTML代码全部放到模板里，写起来更有效率。
二十一、异步IO
	1.另一种解决IO问题的方法是异步IO。
		1.当代码需要执行一个耗时的IO操作时，它只发出IO指令，并不等待IO结果，然后就去执行其他代码了。一段时间后，当IO返回结果时，再通知CPU进行处理。
		2.可以想象如果按普通顺序写出的代码实际上是没法完成异步IO的：
			do_some_code()
			f = open('/path/to/file', 'r')
			r = f.read() # <== 线程停在此处等待IO操作结果
			# IO操作完成后线程才能继续执行:
			do_some_code(r)
		3.所以，同步IO模型的代码是无法实现异步IO模型的。
		4.异步IO模型需要一个消息循环，在消息循环中，主线程不断地重复“读取消息-处理消息”这一过程：
			loop = get_event_loop()
			while True:
				event = loop.get_event()
				process_event(event)
		5.在“发出IO请求”到收到“IO完成”的这段时间里，同步IO模型下，主线程只能挂起，但异步IO模型下，主线程并没有休息，而是在消息循环中继续处理其他消息。
		这样，在异步IO模型下，一个线程就可以同时处理多个IO请求，并且没有切换线程的操作。对于大多数IO密集型的应用程序，使用异步IO将大大提升系统的多任务处理能力。
	2.协程
		1.协程，又称微线程，纤程。英文名Coroutine。
		2.协程看上去也是子程序，但执行过程中，在子程序内部可中断，然后转而执行别的子程序，在适当的时候再返回来接着执行。
		3.Python对协程的支持是通过generator实现的。
			1.在generator中，我们不但可以通过for循环来迭代，还可以不断调用next()函数获取由yield语句返回的下一个值。
			2.但是Python的yield不但可以返回一个值，它还可以接收调用者发出的参数。
	小结：
		1.整个流程无锁，由一个线程执行，produce和consumer协作完成任务，所以称为“协程”，而非线程的抢占式多任务。
		2.协程的特点：子程序就是协程的一种特例。
	3.asyncio
		1.asyncio是Python 3.4版本引入的标准库，直接内置了对异步IO的支持。
		2.asyncio的编程模型就是一个消息循环。我们从asyncio模块中直接获取一个EventLoop的引用，然后把需要执行的协程扔到EventLoop中执行，就实现了异步IO。
		3.@asyncio.coroutine把一个generator标记为coroutine类型，然后，我们就把这个coroutine扔到EventLoop中执行。
	小结：
		1.asyncio提供了完善的异步IO支持
		2.异步操作需要在coroutine中通过yield from完成；
		3.多个coroutine可以封装成一组Task然后并发执行。
	4.async/await
		1.用asyncio提供的@asyncio.coroutine可以把一个generator标记为coroutine类型，然后在coroutine内部用yield from调用另一个coroutine实现异步操作。
		2.为了简化并更好地标识异步IO，从Python 3.5开始引入了新的语法async和await，可以让coroutine的代码更简洁易读。
		3.async和await是针对coroutine的新语法，要使用新的语法，只需要做两步简单的替换：
			1.把@asyncio.coroutine替换为async；
			2.把yield from替换为await。
	小结：1.Python从3.5版本开始为asyncio提供了async和await的新语法；
		  2.新语法只能用在Python 3.5以及后续版本，如果使用3.4版本，则仍需使用旧的方案。
	5.aiohttp
		1.asyncio实现了TCP、UDP、SSL等协议，aiohttp则是基于asyncio实现的HTTP框架。
	小结:
		1.其实是eventloop的线程，它执行到IO操作时，暂停后续代码，转而处理下一个event。当IO操作结束后，在从断点处继续执行后续代码
		2.函数的执行方式是调用－返回，可以嵌套
		3.协程的执行方式是执行－遇到IO中断－继续执行，关键是中断的时候线程去执行其他可以执行的协程去了
总结：经过断断续续大概2个多月终于把廖老师的博客看完，正要去做博客的最后一部分"实战",激动，and两个月贴了快1300行博客，
		我也是蛮拼的。。233333
	
	
	